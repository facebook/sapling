// @generated SignedSource<<4b6c0a1cab8d1b04ec162cf56400844a>>
// DO NOT EDIT THIS FILE MANUALLY!
// This file is a mechanical copy of the version in the configerator repo. To
// modify it, edit the copy in the configerator repo instead and copy it over by
// running the following in your fbcode directory:
//
// configerator-thrift-updater scm/mononoke/sharding/sharding.thrift
/*
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This software may be used and distributed according to the terms of the
 * GNU General Public License version 2.
 */

namespace py configerator.mononoke.sharding
namespace py3 mononoke.sharding
namespace cpp2 mononoke.sharding

// NOTICE:
// Don't use 'defaults' for any of these values (e.g. 'bool enabled = true')
// because these structs will be deserialized by serde in rust. The following
// rules apply upon deserialization:
//   1) specified default values are ignored, default values will always be
//      the 'Default::default()' value for a given type. For example, even
//      if you specify:
//          1: bool enabled = true,
//
//       upon decoding, if the field enabled isn't present, the default value
//       will be false.
//
//   2) not specifying optional won't actually make your field required,
//      neither will specifying required make any field required. Upon decoding
//      with serde, all values will be Default::default() and no error will be
//      given.
//
//   3) the only way to detect wether a field was specified in the structure
//      being deserialized is by making a field optional. This will result in
//      a 'None' value for a Option<T> in rust. So the way we can give default
//      values other then 'Default::default()' is by making a field optional,
//      and then explicitly handle 'None' after deserialization.

/// Struct representing the sharding configuration for a repo
/// independent of the type, job or region.
include "thrift/annotation/rust.thrift"
include "configerator/structs/scm/mononoke/sharding/regions.thrift"
include "configerator/structs/scm/mononoke/sharding/processname.thrift"

@rust.Exhaustive
struct RawRepoShard {
  // The number of replicas this repo-shard should have. e.g. If we need 10 instances of
  // fbsource running for a job or request-serving process, then the replica count
  // should be 10.
  1: optional i64 replica_count;
  // The weight of each replica of the repo-shard expressed as a fractional value. e.g. If
  // a replica of aros repo-shard requires 15% of a hosts resources, then the repo-weight is
  // expressed as 0.15. Based on the actual host capacity (say weight = 100,000), this is then
  // converted to an integer value (100,000 * 0.15 = 15,000)
  2: optional float weight;
  // The list of shards that should NOT be co-located with the current repo-shard. e.g. If
  // fbsource should not be co-located with www & configerator, then the conflicting_repo_shards
  // should have the value ['www', 'configerator']
  // NOTE: This feature is not currently supported by SM and will be supported in the future.
  3: optional list<string> conflicting_repo_shards;
  // The list of repo shards that are associated with the given shard. This property can be used
  // for processes involving dual repo processing (e.g. fbsource to ovrsource backsyncer).
  4: optional list<string> associated_repo_shards;
  // The number of chunks to be created for the given repo shard. e.g. When chunks = 10 for repo
  // fbsource, the shards would be created as: fbsource_CHUNK_1-10, fbsource_CHUNK_2-10 and so on.
  // NOTE: If you want multiple tasks to run fbsource without any difference in state, then use
  // replica_count to get miltiple replicas. If you want multiple tasks running fbsource but each
  // to have a different state context (e.g. run X for the first 100K commit of fbsource), then
  // use chunks.
  5: optional i64 chunks;
  // If chunking is enabled, this option controls the size of each chunk to be provided to the job/service.
  // If the chunk size is dynamic and will be determined at runtime (e.g. AliasVerify), then this option
  // should not be set. e.g. When chunks = 10, repo = fbsource and chunk_size = 10000 then the shards would
  // be created as fbsource_CHUNK_1-10_SIZE_10000, fbsource_CHUNK_2-10_SIZE_10000
  6: optional i64 chunk_size;
  // If the repo needs to be chunked but the chunking strategy can be arbitrary then instead of
  // just providing the total number of chunks, we can provide chunks + chunk_list. e.g. When
  // chunks = 10 and chunk_list = [2, 3, 6] then the shards for repo fbsource would be created
  // as fbsource_CHUNK_2-10, fbsource_CHUNK_3-10 and fbsource_CHUNK_6-10
  7: optional list<i64> chunk_list;
  // Suffix to be added to the shardmanager scope for the given repo shard.
  8: optional string scope_suffix;

  // this is to setup placement policy for the shards
  // currently this will be a list of region short names, even though the shard manager support other
  // stickiness types (like dc, server etc.), but they are deprecated
  // hence setting this up in a minimal way to only support that stickiness rule.
  9: optional list<string> preferred_region_list;
}

/// Struct representing the sharding configuration for a repo
/// in the context of a specific job/process with defined region and type.
@rust.Exhaustive
struct RawRepoProcessShard {
  // Flag determining if the current RepoProcessShard is for background process
  // like hg sync or for request serving process like SCS service.
  1: optional bool is_background;
  // Mapping of repo-shard configuration for each distinct region in which the
  // shards can be deployed.
  2: optional map<regions.RawRegion, RawRepoShard> region_repo_shards;
}

/// Struct representing the overall sharding configuration for a repo.
@rust.Exhaustive
struct RawRepoShardingConfig {
  // Mapping of process names to the corresponding process shard configuration
  // for the current repo.
  1: optional map<
    processname.RawProcessName,
    RawRepoProcessShard
  > process_shards;
}

/// Struct representing the mapping of repo-names to their corresponding
/// RawRepoShardingConfig.
@rust.Exhaustive
struct RawShardingConfigs {
  // Mapping of the repo-names to their corresponding RawRepoShardingConfig.
  1: optional map<string, RawRepoShardingConfig> repo_sharding_configs;
  // Mapping of the process names to the overall capacity for that process.
  2: optional map<processname.RawProcessName, i64> process_capacity;
}
